{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用机器学习的手段，来判断图片的最大相似，如果超过60%，即可认为相似\n",
    "#但需要注意一点的是，相似性只能按照图片最大到最小来匹配，小于60%的可以认为两者之间的相似度不存在，分值计算为\n",
    "#0分，大于60%的，按照其相似度大小来计分\n",
    "#返回一个位置和分值的列表\n",
    "#重点要针对下 plot 绘制的那些图片，这很重要\n",
    "#输入为两张彩色的图片，尺寸大小一致\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential,Model, load_model\n",
    "from keras.layers.core import Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D,ZeroPadding2D,Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D,AveragePooling2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import AveragePooling2D,MaxPooling2D,Dropout\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import time\n",
    "import pdb\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(776)\n",
    "paths = \"../../data/Keras/COVID-19/\"\n",
    "epochs = 100\n",
    "height, width = 224,224\n",
    "batch_size = 50\n",
    "info_string = \"now\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16(nb_classes, num_input_channels=1024):\n",
    "    \"\"\"\n",
    "    Build Convolution Neural Network\n",
    "    args : nb_classes (int) number of classes\n",
    "    returns : model (keras NN) the Neural Net model\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(224, 224,3)))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(AveragePooling2D((7, 7)))\n",
    "    model.add(Flatten())\n",
    "    # Add the W layer\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    model.name = \"VGG16\"\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readPath(paths):\n",
    "    imgs_path = []\n",
    "    for path in os.listdir(paths):\n",
    "        if(not os.path.isfile(paths+path)):\n",
    "            for filename in (os.listdir(paths+path)):\n",
    "                if (filename.endswith('.jpg') or filename.endswith('.png')):\n",
    "                    imgs_path.append(paths+path+'/'+filename)\n",
    "                else:\n",
    "                    print(\"erros file1 is %s\"%filename)\n",
    "    #数据集打散然后重新组合，因为训练过程中会导致前面训练的类别被弱化\n",
    "    random.shuffle(imgs_path)\n",
    "    #pdb.set_trace()\n",
    "    return (imgs_path)\n",
    "def readData(path):\n",
    "    imgs = []\n",
    "    labs = []\n",
    "    for filename in path:\n",
    "        if ( \"CT_COVID\" in filename):\n",
    "            labs.append([0,1])\n",
    "            #pdb.set_trace()\n",
    "        elif (\"CT_NonCOVID\" in filename):\n",
    "            labs.append([1,0])\n",
    "        else:\n",
    "            print(\"erros file2 is %s\"%filename)\n",
    "            #sys.exit()\n",
    "        #filename = path + '/' + filename\n",
    "        img = cv2.imread(filename)\n",
    "        img = cv2.resize(img, (height, width))\n",
    "        if( \"2020.01.24.919183-p27-132\" in filename):\n",
    "            plt.imshow(img)\n",
    "        #图片归一化处理\n",
    "        imgs.append(img)\n",
    "    return np.array(imgs),np.array(labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "def train(model,checkpoint,learning_rate_reduction,imgs_path):\n",
    "    for epoch in range(epochs):\n",
    "        # 记录时间\n",
    "        num_steps_burn_in = 10\n",
    "        # 先定义预热轮数（头几轮跌代有显存加载、cache命中等问题因此可以跳过，只考量10轮迭代之后的计算时间）\n",
    "        total_duration = 0.0 \n",
    "        # 记录总时间\n",
    "        total_duration_squared = 0.0 \n",
    "        # 总时间平方和  -----用来后面计算方差\n",
    "        start_time = time.time() \n",
    "        for i in range(int(len(imgs_path) / batch_size)):\n",
    "            print('%.3f / %.3f<=====>%.3f / %.3f'%(epoch,epochs,i,int(len(imgs_path) / batch_size)))\n",
    "            if ((i+1)*batch_size <= len(imgs_path)):\n",
    "\n",
    "                train_x,train_y = readData(imgs_path[i*batch_size:(i+1)*batch_size])\n",
    "            else:\n",
    "                train_x,train_y = readData(imgs_path[i**batch_size:])\n",
    "            start_time = time.time() \n",
    "            # 记录时间\n",
    "            #pdb.set_trace()\n",
    "            #\n",
    "            model.fit(train_x, train_y, epochs=1, batch_size=batch_size,callbacks=[checkpoint,learning_rate_reduction])\n",
    "            model.predict(train_x,batch_size=batch_size,verbose=0)\n",
    "            #pdb.set_trace()\n",
    "            #每十轮输出一次\n",
    "            duration = time.time() - start_time\n",
    "            #每十轮输出一次\n",
    "            if i >= num_steps_burn_in:\n",
    "                if not i % 10:\n",
    "                    print ('%s: step %d, duration = %.3f' %\n",
    "                   (datetime.now(), i - num_steps_burn_in, duration))\n",
    "            total_duration += duration  \n",
    "            # 累加便于后面计算每轮耗时的均值和标准差\n",
    "            total_duration_squared += duration * duration\n",
    "        mn = total_duration / int(len(imgs_path) / batch_size) # 每轮迭代的平均耗时\n",
    "        vr = total_duration_squared / int(len(imgs_path) / batch_size) - mn * mn\n",
    "        # 方差，是把一般的方差公式进行化解之后的结果，值得 借鉴\n",
    "        sd = math.sqrt(vr) # 标准差\n",
    "        print ('%s: %s across %d steps, %.3f +/- %.3f sec / batch' %\n",
    "             (datetime.now(), info_string, int(len(imgs_path) / batch_size), mn, sd))\n",
    "    #保存模型到本地\n",
    "    model.save(os.path.join('./', 'my_model.h5'))\n",
    "    model.save_weights(os.path.join('./', 'deep_dream.hdf5'))\n",
    "\n",
    "#训练测试\n",
    "def test(use_local_model, imgs_path):\n",
    "    total_duration = 0.0 \n",
    "    # 记录总时间\n",
    "    total_duration_squared = 0.0 \n",
    "    if (use_local_model):\n",
    "        model = load_model(os.path.join('./', 'my_model.h5'))\n",
    "    error_sum = 0\n",
    "    for i in range(int(len(imgs_path) / batch_size)):\n",
    "        num_steps_burn_in = 10\n",
    "        start_time = time.time() \n",
    "        if ((i+1)*batch_size <= len(imgs_path)):\n",
    "            test_x,test_y = readData(imgs_path[i*batch_size:(i+1)*batch_size])\n",
    "        else:\n",
    "            test_x,test_y = readData(imgs_path[i*batch_size:])\n",
    "        start_time = time.time() \n",
    "        # 记录时间\n",
    "        y=model.predict(test_x,batch_size=batch_size,verbose=0)\n",
    "        #每十轮输出一次\n",
    "        duration = time.time() - start_time\n",
    "        #每十轮输出一次\n",
    "        if i >= num_steps_burn_in:\n",
    "            if not i % 10:\n",
    "                print ('%s: step %d, duration = %.3f' %\n",
    "               (datetime.now(), i - num_steps_burn_in, duration))\n",
    "        total_duration += duration  \n",
    "        # 累加便于后面计算每轮耗时的均值和标准差\n",
    "        total_duration_squared += duration * duration\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            #pdb.set_trace()\n",
    "            if ((np.round(y[j])==test_y[j]).all()):\n",
    "                pass\n",
    "            else:\n",
    "                error_sum += 1\n",
    "        #pdb.set_trace()\n",
    "        print(\"正确率 acc predict is %.3f\"%(1-(error_sum/batch_size)))\n",
    "        error_sum = 0\n",
    "\n",
    "    mn = total_duration / int(len(imgs_path) / batch_size) # 每轮迭代的平均耗时\n",
    "    vr = total_duration_squared / int(len(imgs_path) / batch_size) - mn * mn\n",
    "    # 方差，是把一般的方差公式进行化解之后的结果，值得 借鉴\n",
    "    sd = math.sqrt(vr) # 标准差\n",
    "    print ('%s: %s across %d steps, %.3f +/- %.3f sec / batch' %\n",
    "             (datetime.now(), info_string, int(len(imgs_path) / batch_size), mn, sd))\n",
    "    #print(y,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    imgs_path = readPath(paths)\n",
    "    np.random.shuffle(imgs_path)\n",
    "    imgs_path_train = imgs_path[0 : int(len(imgs_path)*0.8)]\n",
    "    imgs_path_test  = imgs_path[int(len(imgs_path)*0.8) : ]\n",
    "    nb_classes, num_input_channels = 2 , 1024\n",
    "    model = VGG16(nb_classes, num_input_channels)\n",
    "    model.summary()\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=1, factor=0.1, min_lr=0.001)\n",
    "    model.compile(optimizer=\"sgd\", loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    checkpoint = ModelCheckpoint('weights.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max', period=1)\n",
    "    #使用已经训练好的网络或者重新训练网络\n",
    "    use_local_model = True\n",
    "    train(model,checkpoint,learning_rate_reduction,imgs_path_train)\n",
    "    test(use_local_model,imgs_path_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
